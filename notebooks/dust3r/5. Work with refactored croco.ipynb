{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8b01f46-7255-4b02-aecd-99208158139b",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a33080c-921f-4b5f-8373-477481fd69f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# dust3r_path = str(Path(os.path.join(os.getcwd())).parent / \"dust3r\" / \"dust3r\")\n",
    "# sys.path.append(dust3r_path)\n",
    "sys.path.append(\"../../dust3r\")\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07a60740-13a5-4577-b676-8ab1f76a184b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mannotated\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdust3r\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdust3r\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AnnotatedAsymmetricCroCo3DStereo \u001b[38;5;28;01mas\u001b[39;00m AsymmetricCroCo3DStereo\n",
      "File \u001b[0;32m~/Documents/Projects/annotated-dust3r/notebooks/dust3r/../../src/annotated/dust3r/dust3r.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcroco\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcroco\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AnnotatedCroCo\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mheads\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m head_factory\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fill_default_args, freeze_all_params, interleave, is_symmetrized, transpose_to_landscape\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(model_path, device):\n",
      "File \u001b[0;32m~/Documents/Projects/annotated-dust3r/notebooks/dust3r/../../src/annotated/dust3r/heads.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meinops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rearrange\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01micecream\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ic\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdpt_block\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DPTOutputAdapter  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdust3r\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath_to_croco\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdust3r\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mheads\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpostprocess\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m postprocess\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "from src.annotated.dust3r.dust3r import AnnotatedAsymmetricCroCo3DStereo as AsymmetricCroCo3DStereo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53139cd3-38b4-4aa2-80aa-3518bc62734a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "batch_size = 1\n",
    "schedule = \"cosine\"\n",
    "lr = 0.01\n",
    "niter = 300\n",
    "\n",
    "model_name = \"naver/DUSt3R_ViTLarge_BaseDecoder_512_dpt\"\n",
    "# you can put the path to a local checkpoint in model_name if needed\n",
    "model = AsymmetricCroCo3DStereo.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b32151eb-3cfd-4087-97d8-0f260fc54829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from src.dust3r.load_images import LoadConfig, load_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b165c468-11d5-48c4-ab85-02372b8c08cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.load_images:>> Loading 4 images.\n",
      "INFO:src.load_images: - Added assets/house/IMG_0251.jpeg with resolution 384x512\n",
      "INFO:src.load_images: - Added assets/house/IMG_0252.jpeg with resolution 384x512\n",
      "INFO:src.load_images: - Added assets/house/IMG_0253.jpeg with resolution 384x512\n",
      "INFO:src.load_images: - Added assets/house/IMG_0254.jpeg with resolution 384x512\n",
      "INFO:src.load_images: (Successfully loaded 4 images)\n"
     ]
    }
   ],
   "source": [
    "image_paths = [\n",
    "    \"assets/house/IMG_0251.jpeg\",\n",
    "    \"assets/house/IMG_0252.jpeg\",\n",
    "    \"assets/house/IMG_0253.jpeg\",\n",
    "    \"assets/house/IMG_0254.jpeg\",\n",
    "]\n",
    "images_data = load_images(image_paths, config=LoadConfig(size=512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f173f470-2b28-4592-bc4c-4fbc5e4e634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.make_pairs import make_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "021bdcee-bb7e-4bdf-8274-c56b1edda925",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = make_pairs(images_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1340cf-8faf-4b20-98c5-a57f690cc5c7",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcce410c-cce6-4273-af5a-cef0f3c49ea0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdust3r\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collate_with_cat, inference, loss_of_one_batch\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "from src.inference import collate_with_cat, inference, loss_of_one_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1e021ba-8ff3-4366-9aa6-1121558fb9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "dict_pairs = [(p[0].to_dict(), p[1].to_dict()) for p in pairs]\n",
    "collated_dict_pairs = collate_with_cat(dict_pairs[0:batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b336c4d-b228-48ed-bd74-71ddde24e496",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = loss_of_one_batch(collated_dict_pairs, model, criterion=None, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa04d1de-a9ad-4728-9018-5b2db3b987c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Inference with model on 12 image pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [05:11<00:00, 51.95s/it]\n"
     ]
    }
   ],
   "source": [
    "output = inference(pairs, model, device, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067409e6-d5cc-42a6-b876-2c6e85d6a40d",
   "metadata": {},
   "source": [
    "## Global Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4096810a-f5b1-4ed5-9e66-b29039d454d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.optimizer import PointCloudOptimizer\n",
    "\n",
    "view1, pred1 = output[\"view1\"], output[\"pred1\"]\n",
    "view2, pred2 = output[\"view2\"], output[\"pred2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4bb8cdd-d617-4035-b19f-7884d94c3327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.3400) tensor(0.8500)\n",
      "tensor(-0.8543) tensor(0.8523)\n"
     ]
    }
   ],
   "source": [
    "# this is the relative distance computed up to a scale factor\n",
    "print(torch.min(pred1[\"pts3d\"]), torch.max(pred1[\"pts3d\"]))\n",
    "print(torch.min(pred2[\"pts3d_in_other_view\"]), torch.max(pred2[\"pts3d_in_other_view\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "057ec7ad-01b9-41ec-858b-41d268581fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0000) tensor(23.1831)\n",
      "tensor(1.0000) tensor(14.2556)\n"
     ]
    }
   ],
   "source": [
    "# this is computed as conf = 1 + exp(conf_for_network_output)\n",
    "print(torch.min(pred1[\"conf\"]), torch.max(pred1[\"conf\"]))\n",
    "print(torch.min(pred2[\"conf\"]), torch.max(pred2[\"conf\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57289008-fb35-4e0e-9b97-7e74e62c3a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = PointCloudOptimizer(view1, view2, pred1, pred2, device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "483b20a9-7da4-4448-82f0-7d34f734ad1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " init edge (2*,3*) score=16.611814498901367\n",
      " init edge (1,2*) score=38.26947784423828\n",
      " init edge (0,1*) score=115.91004943847656\n",
      " init loss = 0.0010532001033425331\n",
      "Global alignement - optimizing for:\n",
      "['pw_poses', 'pw_adaptors', 'im_poses', 'im_depthmaps', 'im_focals']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [01:37<00:00,  3.07it/s, lr=1.27413e-06 loss=0.000220726]\n"
     ]
    }
   ],
   "source": [
    "import roma\n",
    "import torch.nn as nn\n",
    "from src.minimum_spanning_tree import geotrf, get_med_dist_between_poses, init_minimum_spanning_tree\n",
    "from src.utils import xy_grid, signed_expm1, signed_log1p\n",
    "\n",
    "loss = scene.compute_global_alignment_v2(init=\"mst\", niter=300, schedule=schedule, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53844ec5-dc4d-424d-b6dc-18e455ea87db",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.show(viewer=\"gl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74543f2c-9535-4423-a428-c6180efab2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(scene.imgs) == 2\n",
    "assert scene.imgs[0].shape == (384, 512, 3)\n",
    "assert len(scene.get_pts3d()) == 2\n",
    "assert scene.get_pts3d()[0].shape == torch.Size([384, 512, 3])\n",
    "assert len(scene.get_masks()) == 2\n",
    "assert scene.get_masks()[0].shape == torch.Size([384, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ce3433-9f98-48ae-ae13-26770ae26724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve useful values from scene:\n",
    "imgs = scene.imgs\n",
    "focals = scene.get_focals()\n",
    "poses = scene.get_im_poses()\n",
    "pts3d = scene.get_pts3d()\n",
    "confidence_masks = scene.get_masks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1536796-3759-46f1-bdac-10f10c348dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find 2D-2D matches between the two images\n",
    "from dust3r.utils.geometry import find_reciprocal_matches, xy_grid\n",
    "\n",
    "pts2d_list, pts3d_list = [], []\n",
    "for i in range(2):\n",
    "    conf_i = confidence_masks[i].cpu().numpy()\n",
    "    pts2d_list.append(xy_grid(*imgs[i].shape[:2][::-1])[conf_i])  # imgs[i].shape[:2] = (H, W)\n",
    "    pts3d_list.append(pts3d[i].detach().cpu().numpy()[conf_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35ef89a-1348-4540-9eef-50175ed0e613",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert imgs[0].shape[:2][::-1] == (512, 384)\n",
    "\n",
    "assert confidence_masks[0].cpu().numpy().shape == (384, 512)\n",
    "assert xy_grid(*imgs[0].shape[:2][::-1]).shape == (384, 512, 2)\n",
    "assert pts3d[0].detach().cpu().numpy().shape == (384, 512, 3)\n",
    "\n",
    "# number of points selected for 2d should be the same as the mask where pixels are True\n",
    "assert np.sum(confidence_masks[0].cpu().numpy()) == len(pts2d_list[0])\n",
    "assert np.sum(confidence_masks[0].cpu().numpy()) == len(pts3d_list[0])\n",
    "\n",
    "assert imgs[1].shape[:2][::-1] == (512, 384)\n",
    "\n",
    "assert confidence_masks[1].cpu().numpy().shape == (384, 512)\n",
    "assert xy_grid(*imgs[1].shape[:2][::-1]).shape == (384, 512, 2)\n",
    "assert pts3d[1].detach().cpu().numpy().shape == (384, 512, 3)\n",
    "\n",
    "# number of points selected for 2d should be the same as the mask where pixels are True\n",
    "assert np.sum(confidence_masks[1].cpu().numpy()) == len(pts2d_list[1])\n",
    "assert np.sum(confidence_masks[1].cpu().numpy()) == len(pts3d_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f94393-235c-400d-8d32-e0a19ba23647",
   "metadata": {},
   "outputs": [],
   "source": [
    "reciprocal_in_P2, nn2_in_P1, num_matches = find_reciprocal_matches(*pts3d_list)\n",
    "print(f\"found {num_matches} matches\")\n",
    "matches_im1 = pts2d_list[1][reciprocal_in_P2]\n",
    "matches_im0 = pts2d_list[0][nn2_in_P1][reciprocal_in_P2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf40742e-084f-4d1f-961a-843618a064d1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# visualize a few matches\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as pl\n",
    "\n",
    "n_viz = 10\n",
    "match_idx_to_viz = np.round(np.linspace(0, num_matches - 1, n_viz)).astype(int)\n",
    "viz_matches_im0, viz_matches_im1 = (\n",
    "    matches_im0[match_idx_to_viz],\n",
    "    matches_im1[match_idx_to_viz],\n",
    ")\n",
    "\n",
    "H0, W0, H1, W1 = *imgs[0].shape[:2], *imgs[1].shape[:2]\n",
    "img0 = np.pad(imgs[0], ((0, max(H1 - H0, 0)), (0, 0), (0, 0)), \"constant\", constant_values=0)\n",
    "img1 = np.pad(imgs[1], ((0, max(H0 - H1, 0)), (0, 0), (0, 0)), \"constant\", constant_values=0)\n",
    "img = np.concatenate((img0, img1), axis=1)\n",
    "pl.figure()\n",
    "pl.imshow(img)\n",
    "cmap = pl.get_cmap(\"jet\")\n",
    "for i in range(n_viz):\n",
    "    (x0, y0), (x1, y1) = viz_matches_im0[i].T, viz_matches_im1[i].T\n",
    "    pl.plot(\n",
    "        [x0, x1 + W0],\n",
    "        [y0, y1],\n",
    "        \"-+\",\n",
    "        color=cmap(i / (n_viz - 1)),\n",
    "        scalex=False,\n",
    "        scaley=False,\n",
    "    )\n",
    "pl.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64996890-e346-402f-8780-e57664303af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e900b976-21fa-4dc3-9ccc-1e607f95b77a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "annotated-dust3r",
   "language": "python",
   "name": "annotated-dust3r"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
