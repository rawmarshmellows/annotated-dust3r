{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dd4b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable auto-reloading of modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Enable inline plotting for Jupyter notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import math\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.transforms\n",
    "from icecream import ic\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(\"../../..\")\n",
    "\n",
    "from src.annotated.croco.croco import AnnotatedCroCo\n",
    "from src.annotated.losses.masked_mse import AnnotatedMaskedMSE\n",
    "\n",
    "ic.disable()\n",
    "\n",
    "\n",
    "def visualize_croco_output(model, out, mask, image1, image2, imagenet_std_tensor, imagenet_mean_tensor):\n",
    "    \"\"\"\n",
    "    Create visualization for CroCo model output.\n",
    "\n",
    "    Args:\n",
    "        model: The CroCo model instance\n",
    "        out: Model output tensor\n",
    "        mask: Mask tensor from model\n",
    "        image1: Input image tensor\n",
    "        image2: Reference image tensor\n",
    "        imagenet_std_tensor: ImageNet standardization tensor\n",
    "        imagenet_mean_tensor: ImageNet mean tensor\n",
    "\n",
    "    Returns:\n",
    "        PIL Image containing the visualization\n",
    "    \"\"\"\n",
    "    # Debug: Process model output to create visualization\n",
    "\n",
    "    # the output is normalized, thus use the mean/std of the actual image to go back to RGB space\n",
    "    patchified = model.patchify(image1)\n",
    "    mean = patchified.mean(dim=-1, keepdim=True)\n",
    "    var = patchified.var(dim=-1, keepdim=True)\n",
    "    decoded_image = model.unpatchify(out * (var + 1.0e-6) ** 0.5 + mean)\n",
    "    # undo imagenet normalization, prepare masked image\n",
    "    decoded_image = decoded_image * imagenet_std_tensor + imagenet_mean_tensor\n",
    "    input_image = image1 * imagenet_std_tensor + imagenet_mean_tensor\n",
    "    ref_image = image2 * imagenet_std_tensor + imagenet_mean_tensor\n",
    "    image_masks = model.unpatchify(model.patchify(torch.ones_like(ref_image)) * mask[:, :, None])\n",
    "    masked_input_image = (1 - image_masks) * input_image\n",
    "\n",
    "    # make visualization\n",
    "    visualization = torch.cat(\n",
    "        (ref_image, masked_input_image, decoded_image, input_image), dim=3\n",
    "    )  # 4*(B, 3, H, W) -> B, 3, H, W*4\n",
    "    B, C, H, W = visualization.shape\n",
    "    visualization = visualization.permute(1, 0, 2, 3).reshape(C, B * H, W)\n",
    "    visualization = torchvision.transforms.functional.to_pil_image(torch.clamp(visualization, 0, 1))\n",
    "\n",
    "    return visualization\n",
    "\n",
    "    # # Convert to PIL image for display/saving\n",
    "    # return Image.fromarray((visualization.cpu().numpy() * 255).astype(\"uint8\"))\n",
    "\n",
    "\n",
    "def display(img):\n",
    "    \"\"\"\n",
    "    Display an image in the notebook.\n",
    "\n",
    "    Args:\n",
    "        img: PIL Image to display\n",
    "    \"\"\"\n",
    "    # Debug: Custom display function for notebook visualization\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Debug: Check for MPS (Metal Performance Shaders) availability for Apple Silicon (M-series)\n",
    "# device = torch.device(\n",
    "#     \"mps\"\n",
    "#     if torch.backends.mps.is_available()\n",
    "#     else (\"cuda:0\" if torch.cuda.is_available() and torch.cuda.device_count() > 0 else \"cpu\")\n",
    "# )\n",
    "device = \"cpu\"\n",
    "print(f\"Using device: {device}\")  # Debug output to confirm device selection\n",
    "\n",
    "model = AnnotatedCroCo(img_size=224, patch_size=16, pos_embed=\"RoPE100\").to(device)\n",
    "loss_fn = AnnotatedMaskedMSE(norm_pix_loss=True, masked=True)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# Create sample inputs\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_mean_tensor = torch.tensor(imagenet_mean).view(1, 3, 1, 1).to(device, non_blocking=True)\n",
    "imagenet_std = [0.229, 0.224, 0.225]\n",
    "imagenet_std_tensor = torch.tensor(imagenet_std).view(1, 3, 1, 1).to(device, non_blocking=True)\n",
    "trfs = Compose([ToTensor(), Normalize(mean=imagenet_mean, std=imagenet_std)])\n",
    "image1 = trfs(Image.open(\"data/Chateau1.png\").convert(\"RGB\")).to(device, non_blocking=True).unsqueeze(0)\n",
    "image2 = trfs(Image.open(\"data/Chateau2.png\").convert(\"RGB\")).to(device, non_blocking=True).unsqueeze(0)\n",
    "\n",
    "\n",
    "# Forward pass\n",
    "loss_value = math.inf\n",
    "\n",
    "# Initialize progress bar and step counter\n",
    "max_steps = 5000\n",
    "plot_every = 10\n",
    "pbar = tqdm(desc=\"Training\", leave=True, total=max_steps)\n",
    "step = -1\n",
    "\n",
    "# Debug: Training loop with visualization every 5 steps\n",
    "while loss_value > 0.01 and step < max_steps:\n",
    "    # Forward pass\n",
    "    out, mask, target = model(image1, image2)\n",
    "    loss = loss_fn(out, mask, target)\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Update loss value and progress bar\n",
    "    loss_value = loss.item()\n",
    "    pbar.set_postfix({\"loss\": f\"{loss_value:.4f}\"})\n",
    "    pbar.update(1)\n",
    "\n",
    "    # Increment step counter\n",
    "    step += 1\n",
    "\n",
    "    # Generate and display visualization every 100 steps\n",
    "    if step % plot_every == 0:\n",
    "        with torch.inference_mode():\n",
    "            out, mask, target = model(image1, image2)\n",
    "\n",
    "        # Generate visualization using the function\n",
    "        step_visualization = visualize_croco_output(\n",
    "            model, out, mask, image1, image2, imagenet_std_tensor, imagenet_mean_tensor\n",
    "        )\n",
    "\n",
    "        # Display the visualization\n",
    "        display(step_visualization)\n",
    "        print(f\"Step {step}, Loss: {loss_value:.4f}\")\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9643c40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc1d1118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb50fb2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "annotated-dust3r",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
